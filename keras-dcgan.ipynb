{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN for Fashion MNIST\n",
    "DCGAN (Deep Convolutional Generative Adversarial Networks) is one of the most controversial models for generating synthetic images from a given distribution.<br><hr>\n",
    "In this notebook we will look at how we cant generate fashion images using the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "            Conv2D(64, (5, 5),\n",
    "            padding='same',\n",
    "            input_shape=(28, 28, 1))\n",
    "            )\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch-wise training\n",
    "- Train Discriminator\n",
    "- Train GAN (Generator + Discriminator)\n",
    "- Discriminator: Minimize loss\n",
    "- Generator: Maximize probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    if !os.path.exists(\"images\"):\n",
    "        os.makedirs(\"images\")\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    # X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])\n",
    "    d = discriminator_model()\n",
    "    g = generator_model()\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\"images/\"+\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            # print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "            d.trainable = False\n",
    "            g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "            d.trainable = True\n",
    "            # print(\"batch %d d_loss : %f g_loss : %f\" % (index, d_loss, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Images after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice=False):\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tej/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 937\n",
      "Epoch is 1\n",
      "Number of batches 937\n",
      "Epoch is 2\n",
      "Number of batches 937\n",
      "Epoch is 3\n",
      "Number of batches 937\n",
      "Epoch is 4\n",
      "Number of batches 937\n",
      "Epoch is 5\n",
      "Number of batches 937\n",
      "Epoch is 6\n",
      "Number of batches 937\n",
      "Epoch is 7\n",
      "Number of batches 937\n",
      "Epoch is 8\n",
      "Number of batches 937\n",
      "Epoch is 9\n",
      "Number of batches 937\n",
      "Epoch is 10\n",
      "Number of batches 937\n",
      "Epoch is 11\n",
      "Number of batches 937\n",
      "Epoch is 12\n",
      "Number of batches 937\n",
      "Epoch is 13\n",
      "Number of batches 937\n",
      "Epoch is 14\n",
      "Number of batches 937\n",
      "Epoch is 15\n",
      "Number of batches 937\n",
      "Epoch is 16\n",
      "Number of batches 937\n",
      "Epoch is 17\n",
      "Number of batches 937\n",
      "Epoch is 18\n",
      "Number of batches 937\n",
      "Epoch is 19\n",
      "Number of batches 937\n",
      "Epoch is 20\n",
      "Number of batches 937\n",
      "Epoch is 21\n",
      "Number of batches 937\n",
      "Epoch is 22\n",
      "Number of batches 937\n",
      "Epoch is 23\n",
      "Number of batches 937\n",
      "Epoch is 24\n",
      "Number of batches 937\n",
      "Epoch is 25\n",
      "Number of batches 937\n",
      "Epoch is 26\n",
      "Number of batches 937\n",
      "Epoch is 27\n",
      "Number of batches 937\n",
      "Epoch is 28\n",
      "Number of batches 937\n",
      "Epoch is 29\n",
      "Number of batches 937\n",
      "Epoch is 30\n",
      "Number of batches 937\n",
      "Epoch is 31\n",
      "Number of batches 937\n",
      "Epoch is 32\n",
      "Number of batches 937\n",
      "Epoch is 33\n",
      "Number of batches 937\n",
      "Epoch is 34\n",
      "Number of batches 937\n",
      "Epoch is 35\n",
      "Number of batches 937\n",
      "Epoch is 36\n",
      "Number of batches 937\n",
      "Epoch is 37\n",
      "Number of batches 937\n",
      "Epoch is 38\n",
      "Number of batches 937\n",
      "Epoch is 39\n",
      "Number of batches 937\n",
      "Epoch is 40\n",
      "Number of batches 937\n",
      "Epoch is 41\n",
      "Number of batches 937\n",
      "Epoch is 42\n",
      "Number of batches 937\n",
      "Epoch is 43\n",
      "Number of batches 937\n",
      "Epoch is 44\n",
      "Number of batches 937\n",
      "Epoch is 45\n",
      "Number of batches 937\n",
      "Epoch is 46\n",
      "Number of batches 937\n",
      "Epoch is 47\n",
      "Number of batches 937\n",
      "Epoch is 48\n",
      "Number of batches 937\n",
      "Epoch is 49\n",
      "Number of batches 937\n",
      "Epoch is 50\n",
      "Number of batches 937\n",
      "Epoch is 51\n",
      "Number of batches 937\n",
      "Epoch is 52\n",
      "Number of batches 937\n",
      "Epoch is 53\n",
      "Number of batches 937\n",
      "Epoch is 54\n",
      "Number of batches 937\n",
      "Epoch is 55\n",
      "Number of batches 937\n",
      "Epoch is 56\n",
      "Number of batches 937\n",
      "Epoch is 57\n",
      "Number of batches 937\n",
      "Epoch is 58\n",
      "Number of batches 937\n",
      "Epoch is 59\n",
      "Number of batches 937\n",
      "Epoch is 60\n",
      "Number of batches 937\n",
      "Epoch is 61\n",
      "Number of batches 937\n",
      "Epoch is 62\n",
      "Number of batches 937\n",
      "Epoch is 63\n",
      "Number of batches 937\n",
      "Epoch is 64\n",
      "Number of batches 937\n",
      "Epoch is 65\n",
      "Number of batches 937\n",
      "Epoch is 66\n",
      "Number of batches 937\n",
      "Epoch is 67\n",
      "Number of batches 937\n",
      "Epoch is 68\n",
      "Number of batches 937\n",
      "Epoch is 69\n",
      "Number of batches 937\n",
      "Epoch is 70\n",
      "Number of batches 937\n",
      "Epoch is 71\n",
      "Number of batches 937\n",
      "Epoch is 72\n",
      "Number of batches 937\n",
      "Epoch is 73\n",
      "Number of batches 937\n",
      "Epoch is 74\n",
      "Number of batches 937\n",
      "Epoch is 75\n",
      "Number of batches 937\n",
      "Epoch is 76\n",
      "Number of batches 937\n",
      "Epoch is 77\n",
      "Number of batches 937\n",
      "Epoch is 78\n",
      "Number of batches 937\n",
      "Epoch is 79\n",
      "Number of batches 937\n",
      "Epoch is 80\n",
      "Number of batches 937\n",
      "Epoch is 81\n",
      "Number of batches 937\n",
      "Epoch is 82\n",
      "Number of batches 937\n",
      "Epoch is 83\n",
      "Number of batches 937\n",
      "Epoch is 84\n",
      "Number of batches 937\n",
      "Epoch is 85\n",
      "Number of batches 937\n",
      "Epoch is 86\n",
      "Number of batches 937\n",
      "Epoch is 87\n",
      "Number of batches 937\n",
      "Epoch is 88\n",
      "Number of batches 937\n",
      "Epoch is 89\n",
      "Number of batches 937\n",
      "Epoch is 90\n",
      "Number of batches 937\n",
      "Epoch is 91\n",
      "Number of batches 937\n",
      "Epoch is 92\n",
      "Number of batches 937\n",
      "Epoch is 93\n",
      "Number of batches 937\n",
      "Epoch is 94\n",
      "Number of batches 937\n",
      "Epoch is 95\n",
      "Number of batches 937\n",
      "Epoch is 96\n",
      "Number of batches 937\n",
      "Epoch is 97\n",
      "Number of batches 937\n",
      "Epoch is 98\n",
      "Number of batches 937\n",
      "Epoch is 99\n",
      "Number of batches 937\n"
     ]
    }
   ],
   "source": [
    "train(BATCH_SIZE=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tej/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 2s 2ms/step\n",
      "1280/1280 [==============================] - 0s 241us/step\n"
     ]
    }
   ],
   "source": [
    "generate(BATCH_SIZE=64, nice=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fashion Generated](generated_image.png \"Fashion Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
